{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given weights, find analog states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from loaddata import load_cesm2_by_period\n",
    "from utils import *\n",
    "from ocean_basin import *\n",
    "from analog import *\n",
    "from eval_pred import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp, epoch = 'unet4-256_scaled_month01_lr1.5e-05_0', None\n",
    "test_data = 'test'\n",
    "\n",
    "out_dir = f'../output/{exp}'\n",
    "if test_data == 'test':\n",
    "    data_dir = '../data/cesm2'\n",
    "elif test_data == 'real':\n",
    "    data_dir = '../data/real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read history & hyperparameters\n",
    "out_dir = f'../output/{exp}'\n",
    "if epoch is None:\n",
    "    history = pd.read_csv(f'{out_dir}/history.csv', index_col=0)\n",
    "    epoch = history['val_mse'].argmin()\n",
    "\n",
    "with open(f'{out_dir}/hyperparameters.json', 'r') as f:\n",
    "    hp = json.load(f)\n",
    "    hp = DotDict(hp)\n",
    "\n",
    "# MA indices\n",
    "ma_idx_base = xr.open_dataarray(f'{out_dir}/ma_index_{test_data}_epoch{epoch}.nc')\n",
    "ma_idx_base = ma_idx_base.stack(sample=['ens', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(datasets, dataloaders, \n",
    " t0_library, t0_mask, \n",
    " t1_library) = load_cesm2_by_period(data_dir, **hp, shuffle=False)\n",
    "\n",
    "# Get a dataset\n",
    "ds = datasets[test_data].t0_ds\n",
    "\n",
    "# To tensor\n",
    "x = torch.from_numpy(ds.to_array().transpose('sample', ...).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO_PO\n"
     ]
    }
   ],
   "source": [
    "# Read weights\n",
    "weight = xr.open_dataset(f'{out_dir}/weight_{test_data}_epoch{epoch}.nc')\n",
    "\n",
    "# sample dim\n",
    "weight = weight.stack(sample=['ens', 'year'])\n",
    "\n",
    "# Normalize weight\n",
    "weight = weight / weight.to_array().sum(dim=['variable', 'lat', 'lon']) * 100\n",
    "\n",
    "# Ocean basins\n",
    "basin_da = basin_mask(weight.isel(sample=0)[hp.vnames[0]])\n",
    "basins = np.array(['IO', 'PO', 'AO'])\n",
    "\n",
    "# Select basins to retain\n",
    "ibasins = np.array([1, 2])\n",
    "# ibasins = np.array([3])\n",
    "basin_str = '_'.join(basins[ibasins - 1])\n",
    "print(basin_str)\n",
    "cond = xr.concat([(basin_da == ibasin) for ibasin in ibasins], dim='basin').any(dim='basin')\n",
    "weight = weight.where(cond, 0)\n",
    "\n",
    "# To tensor\n",
    "weight = torch.from_numpy(weight.to_array().transpose('sample', ...).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "t0_library = t0_library.to(device)\n",
    "t0_mask = t0_mask.to(device)\n",
    "weight = weight.to(device)\n",
    "x = x.to(device)\n",
    "\n",
    "# Mask weight\n",
    "weight = torch.where(t0_mask[None], 0, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = x.shape[0]\n",
    "\n",
    "# Weighted initial distance\n",
    "d0 = torch.stack([\n",
    "    ((x[i] - t0_library) ** 2 * weight[i]).sum(dim=[1, 2, 3])\n",
    "    for i in range(sample_size)])\n",
    "\n",
    "# Sort\n",
    "ma_idx = torch.argsort(d0)\n",
    "\n",
    "# to cpu\n",
    "ma_idx = ma_idx.cpu().detach().numpy()\n",
    "\n",
    "# insample\n",
    "if test_data == 'train':\n",
    "    ma_idx = ma_idx[:, 1:]\n",
    "\n",
    "# To xarray\n",
    "ma_idx = xr.DataArray(\n",
    "    ma_idx[:, :100], dims=['sample', 'analog'],\n",
    "    coords={'sample': ds['sample']})\n",
    "\n",
    "ma_idx = ma_idx.astype(float).unstack().astype(int)\n",
    "\n",
    "# save\n",
    "ma_idx.to_netcdf(f'{out_dir}/ma_index_{test_data}_epoch{epoch}_{basin_str}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = np.arange(19)\n",
    "vname = 'sst'\n",
    "\n",
    "# Read\n",
    "f = f'{data_dir}/{vname}_anomaly_2x2.nc'\n",
    "da = xr.open_dataarray(f)\n",
    "\n",
    "# Analog forecasts\n",
    "af = get_af_month(\n",
    "    da, hp.month, hp.periods['train'], \n",
    "    ma_idx, hp.n_analog, leads)\n",
    "afm = af.mean(dim='analog')\n",
    "\n",
    "# Time stats\n",
    "t_mse = eval_stats_lead(eval_mse, da, afm, month=hp.month, dim=['ens', 'year'])\n",
    "t_uac = eval_stats_lead(eval_uac, da, afm, month=hp.month, dim=['ens', 'year'])\n",
    "t_cac = eval_stats_lead(eval_r, da, afm, month=hp.month, dim=['ens', 'year'])\n",
    "t_rmsss = eval_stats_lead(eval_rmsss, da, afm, month=hp.month, dim=['ens', 'year'])\n",
    "t_msss = eval_stats_lead(eval_msss, da, afm, month=hp.month, dim=['ens', 'year'])\n",
    "\n",
    "# Over the equatorial Pacific\n",
    "xy_mse = eval_stats_lead(\n",
    "    eval_mse, da.sel(lat=slice(-10, 10), lon=slice(120, 290)), afm, month=hp.month, dim=['lat', 'lon'])\n",
    "xy_uac = eval_stats_lead(\n",
    "    eval_uac, da.sel(lat=slice(-10, 10), lon=slice(120, 290)), afm, month=hp.month, dim=['lat', 'lon'])\n",
    "\n",
    "# Combine\n",
    "t_stats = xr.merge([\n",
    "    t_mse.rename('mse').assign_attrs(long_name='Mean square error'), \n",
    "    t_uac.rename('uac').assign_attrs(long_name='Uncentered anomaly correlation'),\n",
    "    t_cac.rename('cac').assign_attrs(long_name='Centered anomaly correlation'),\n",
    "    t_rmsss.rename('rmsss').assign_attrs(long_name='Root mean square skill score'),\n",
    "    t_msss.rename('msss').assign_attrs(long_name='Mean square skill score'),\n",
    "    ])\n",
    "\n",
    "xy_stats = xr.merge([\n",
    "    xy_mse.rename('mse').assign_attrs(long_name='Mean square error'), \n",
    "    xy_uac.rename('uac').assign_attrs(long_name='Uncentered anomaly correlation')\n",
    "    ])\n",
    "\n",
    "# Save\n",
    "encoding = {key: {'dtype': 'float32'} for key in list(t_stats.keys())}\n",
    "t_stats.to_netcdf(f'{out_dir}/{vname}_t_stats_{test_data}_epoch{epoch}_{basin_str}.nc',\n",
    "                   encoding=encoding)\n",
    "\n",
    "encoding = {key: {'dtype': 'float32'} for key in list(xy_stats.keys())}\n",
    "xy_stats.to_netcdf(f'{out_dir}/{vname}_xy_stats_{test_data}_epoch{epoch}_{basin_str}.nc',\n",
    "                    encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check how many analogs overlap with the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap: 5.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ktoride/.conda/envs/torch/lib/python3.11/site-packages/numpy/core/numeric.py:407: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(res, fill_value, casting='unsafe')\n"
     ]
    }
   ],
   "source": [
    "overlap = (ma_idx.isel(analog=slice(0, hp.n_analog)) \n",
    "           == ma_idx_base.unstack().isel(analog=slice(0, hp.n_analog)))\n",
    "\n",
    "overlap_frac = overlap.sum(dim='analog') / hp.n_analog\n",
    "\n",
    "print(f'Overlap: {overlap_frac.mean().data*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
